# -*- coding: utf-8 -*-
"""Time_Series_Forecasting_using_LSTM_Neural_Network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gsSdYApVC-6RB8vwkRDSB4rQizJPJlyl

In this Python Google Colab Notebook I have used an LSTM Recurrent Deep Neural Network to make a Time-Series Forecasting.
IN this case trying to predict future Comsumptions values based on an hourly Consumption (KW/h) Dataset.
If you replace the CSV File It would adapt to a lot of similar use cases.
"""

# Importing the necesary packages:
import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files

# Upload your .csv file
files.upload()

# Crate a Pandas DatFrame to manage the data of your .csv file
## Put your file name inside the parenthesis
df = pd.read_csv("energy_consumption.csv")
# Visualize the fist raws of the DatFrame
df.head()

# View some general statistics of th data
df.describe()

# General information of the data type
df.info()

# Renaming the columns to be self-expainable
df.columns=["Date", "Consumption"]
df.head()

"""df.columns=["Date", "Consumption"]
df.head(3)
"""

# Configuring plot size
plt.figure(figsize=(20, 3))
# Plotting the featureÂ´s column against the index column
cons = df['Consumption']
cons.plot()

# Viewing the shape of the column (or the number of registers)
cons.shape

# Defining a function to create subsets
def df_to_X_y(df, window_size=12):
  df_as_np = df.to_numpy()
  X = []
  y = []
  for i in range(len(df_as_np)-window_size):
    row = [[a] for a in df_as_np[i:i+window_size]]
    X.append(row)
    label = df_as_np[i+window_size]
    y.append(label)
  return np.array(X), np.array(y)

# Defining vectors to create training and test sets to feed the neural network
WINDOW_SIZE = 12
X1, y1 = df_to_X_y(cons, WINDOW_SIZE)
X1.shape, y1.shape

# Create limits to divide the trainging, validation and test sets
training_limit = int(len(X1) * 0.7)
print(f'training_limit: {training_limit}')

rest = len(X1)-training_limit
print(rest)

validation_limit = int(rest*0.4)
print(f'validation_limit: {validation_limit}')

# Generating training, validation and test sets
X_train1, y_train1 = X1[:training_limit], y1[:training_limit]
X_val1, y_val1 = X1[training_limit:(training_limit+validation_limit)], y1[training_limit:(training_limit+validation_limit)]
X_test1, y_test1 = X1[(training_limit+validation_limit):], y1[(training_limit+validation_limit):]
X_train1.shape, y_train1.shape, X_val1.shape, y_val1.shape, X_test1.shape, y_test1.shape

# Importing packages to create the Neural Network model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam

# If you already have a trained model ("model.h5"), here you can upload it instead of creating a new model
#files.upload()

# import THE TRAINED MODEL
#tf.keras.models.load_model("model1.h5")
#print("The Trianed Model was Imported Succesfully")

# Creating model 1: LSTM Recurrent Deep Neural Network

model1 = Sequential()
model1.add(InputLayer((WINDOW_SIZE, 1)))
model1.add(LSTM(64))
model1.add(Dense(128))
model1.add(Dense(64))
model1.add(Dense(64))
model1.add(Dense(64))
model1.add(Dropout(0.3))
model1.add(Dense(64))
model1.add(Dropout(0.3))
model1.add(Dense(16))
model1.add(Dense(8, 'relu'))
model1.add(Dense(1, 'linear'))

model1.summary()

# Compiling the model
cp1 = ModelCheckpoint('model1/', save_best_only=True)
model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])

# Training process of the Neural Network model
model1.fit(X_train1, y_train1, validation_data=(X_val1, y_val1), epochs=50, callbacks=[cp1])

# Making training predictions
train_predictions = model1.predict(X_train1).flatten()
train_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':y_train1})
train_results[0:20]

### Calculate the Training  Root Mean Squared Error
import math
from sklearn.metrics import mean_squared_error
mse_train1 = math.sqrt(mean_squared_error(train_predictions,y_train1))
print(mse_train1)

# Plotting the training predictions
import matplotlib.pyplot as plt
plt.plot(train_results['Train Predictions'][50:100])
plt.plot(train_results['Actuals'][50:100])

# Making validation predictions
val_predictions = model1.predict(X_val1).flatten()
val_results = pd.DataFrame(data={'Val Predictions':val_predictions, 'Actuals':y_val1})
val_results

mse_val1 = math.sqrt(mean_squared_error(val_predictions,y_val1))
print(mse_val1)

plt.plot(val_results['Val Predictions'][:100])
plt.plot(val_results['Actuals'][:100])

# Making the Test Predictions (future predictions)
test_predictions = model1.predict(X_test1).flatten()
test_results = pd.DataFrame(data={'Test Predictions':test_predictions, 'Actuals':y_test1})
test_results

mse_test1 = math.sqrt(mean_squared_error(test_predictions,y_test1))
print(mse_test1)

cons_max = cons.max()
print(cons_max)

# Calculating the % of Error
Error_percentage = round(((mse_test1*100)/cons_max), 2)
print(Error_percentage)

# Calculating the Model Precision
model1_precision = 100-Error_percentage
print(" The Model Precision is :  ", model1_precision, "%")

plt.figure(figsize=(17, 3))
plt.plot(test_results['Test Predictions'],lw=1)
plt.plot(test_results['Actuals'],lw=1)

from sklearn.metrics import mean_squared_error as mse

def plot_predictions1(model, X, y, start=0, end=2000):
  predictions = model.predict(X).flatten()
  df = pd.DataFrame(data={'Predictions':predictions, 'Actuals':y})
  plt.plot(df['Predictions'][start:end])
  plt.plot(df['Actuals'][start:end])
  return df, mse(y, predictions)

plot_predictions1(model1, X_test1, y_test1)



# Saving the Trained Neural Network Model
model1.save("model1.h5")

!ls

# Downloading the Trained Neural Network Model
from google.colab import files
files.download("model1.h5")







# Creating Model 2:

model2 = Sequential()
model2.add(InputLayer((12, 1)))
model2.add(LSTM(256))
model2.add(Dense(256))
#model2.add(Dense(128))
#model1.add(Dense(64))
#model1.add(Dense(64))
model2.add(Dropout(0.3))
#model1.add(Dense(64))
#model1.add(Dropout(0.3))
#model1.add(Dense(16))
model2.add(Dense(8, 'relu'))
model2.add(Dense(1, 'linear'))

model2.summary()

cp2 = ModelCheckpoint('model2/', save_best_only=True)
model2.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])

model2.fit(X_train1, y_train1, validation_data=(X_val1, y_val1), epochs=60, callbacks=[cp2])



train_predictions2 = model2.predict(X_train1).flatten()
train_results2 = pd.DataFrame(data={'Train Predictions2':train_predictions2, 'Actuals':y_train1})
train_results2[0:20]

# Calculate the Training % of Error (RMSE) performance metrics
import math
from sklearn.metrics import mean_squared_error
mse_train2 = math.sqrt(mean_squared_error(train_predictions2,y_train1))
print(mse_train2)

import matplotlib.pyplot as plt
plt.plot(train_results2['Train Predictions2'][50:100])
plt.plot(train_results2['Actuals'][50:100])

val_predictions2 = model2.predict(X_val1).flatten()
val_results2 = pd.DataFrame(data={'Val Predictions2':val_predictions2, 'Actuals':y_val1})
val_results2

mse_val2 = math.sqrt(mean_squared_error(val_predictions2,y_val1))
print(mse_val2)

plt.plot(val_results2['Val Predictions2'][:100])
plt.plot(val_results2['Actuals'][:100])

test_predictions2 = model2.predict(X_test1).flatten()
test_results2 = pd.DataFrame(data={'Test Predictions2':test_predictions2, 'Actuals':y_test1})
test_results2

mse_test2 = math.sqrt(mean_squared_error(test_predictions2,y_test1))
print(mse_test2)

cons_max = cons.max()
print(cons_max)

# Calculating the % of Error
Error_percentage2 = round(((mse_test2*100)/cons_max), 2)
print(Error_percentage)

# Calculating the Model Precision
model2_precision = 100-Error_percentage2
print(" The Model 2 Precision is :  ", model2_precision, "%")

plt.figure(figsize=(17, 3))
plt.plot(test_results['Test Predictions'],lw=1)
plt.plot(test_results['Actuals'],lw=1)







plt.figure(figsize=(15, 2))
plt.plot(test_results2['Test Predictions2'],lw=2)
plt.plot(test_results2['Actuals'],lw=2)

# Part 2

from sklearn.metrics import mean_squared_error as mse

def plot_predictions2(model, X, y, start=0, end=100):
  predictions = model.predict(X).flatten()
  df = pd.DataFrame(data={'Predictions':predictions, 'Actuals':y})
  plt.plot(df['Predictions'][start:end])
  plt.plot(df['Actuals'][start:end])
  return df, mse(y, predictions)

plot_predictions2(model2, X_test1, y_test1)



model2.save("model2.h5")
!ls

files.download("model2.h5")

# END



m

m

